---
title: New tasks and what matters   
date: 2025-10-01
collection: AI & Society
tags: future, AI, work  
---


# New tasks and what matters 

I remember being invited to a series of loose Zoom meetings during the first or second semester of math undergrad in Stockholm; the organizer was this very creative and somewhat disorganized classmate of mine, always bustling with ideas that seemed very interesting but also terribly far off and impossible to implement. 

One idea he floated was a kind of social network for aspiring entrepreneurs, where their startup (or more generally venture) ideas would get converted to some embedding and then matched against the ideas of other prospective founders. It would be a kind of social network where users hid behind a veil of anonymity, or even one of unawareness, that would only be lifted, with the two matchees revealed to oneanother, once their ideas had been determined a close enough match. 

There are some problems with this; obvious ones I think: There is the well-known quip that ideas are on the whole quite cheap and execution is really what matters. There is also a kind of adverse seletion issue going on, where people with many ideas and loosely held convictions are more likely to want the valiudation of such a matching service. By formalizing the cheaper part of the venture creation process, it draws cognitive resources from the things that matter: The team, strong convictions and the particular connection that the people involved have to the mission... 

This was in 2020 or 2021, and now in 2025 it is very interesting to think of how this is something that is very much feasible on a technical level. The implementation would certainly involve some different technologies than what he envisioned back then, most likely a significant sprinkle of LLMs to be precise, and it would probably be more iterative and interactive, rather than a one-off matching. Even more significantly, one could imagine this kind of mathcing service for other kinds of human activities, matching people based on their interests, researchers based on the questions they are probing and lovers based on their aesthetic sensibilities and values. The latter will probably invite charges of dystopia, and it is certainly not my sincere belief that lovers should primarily match in this way... nor researchers or other curious searchers for that matter. But the general possibility of this and the fact that it might even be an improvement over today's pure technology based methods of matching people, is fascinating. 

I think this raises a broader question of what tasks and activities we want AI to assist with going forward. We will continue to care about the same things: Truth, beauty, ... but when so many new things are possible, things that would have seemed outlandish a few years ago, it becomes pertinent to ask ourselves whether we want to do the same things as before to accomplish a given task, or fulfill a given value; it forces us to think about the reason we are doing things. It is not so much that the above opening anecdote on these zoom meetings and the proposed matching algorithm is that relevant to what I care about, but rather that the experience of seeing it go from pure impossibility to feasible implementation forces me to take a step back. 

## The future of social expression 

One area we should all care about is social expression. By this I mean the way humans interact with each other through technology, and how this changes social dynamics. It is clear with the recent release of the Sora app that OpenAI is moving in the direction of a kind of social network. The integration of Grok of xAI into X further highlight this fusing of AI with the negotiated social feeds. 

There are clear downsides to this: Infinite slop, derivative works with little substance, brainrot, overstimulation.  

In some ways vibe coding is also targeting this axis quite heavily, where the act of creating an app is an expression of creativity, enabled by the AI tool. This is clear in the marketing material of firms like Lovable, especially how it is lauded as a not only a way to build businesses, but also a way for kids to express their creativity. The mobile app vibe coder Bloom makes it even more clear: You can come up with your own quirky design for everyday apps and whisk them away onto the phone of your friend. 

As the initial anecdote and the discussion tied to that shows, there are probably more things one could consider under this rubric and I think we will see some very interesting and *different* things emerge here. 

## The future of external and internal reality   

With the dramatic increase in slop, society will need some way to negotiate and value real inputs. It does matter whether an image is real or not. It matters whether a document at work is based on a full analysis of the relevant background material, if the assumptions are correct, rather than just being the output of quick prompting and pasting some scattered artifacts into context. It certainly matters for long term planning for tasks and projects that extend beyond the current working window of the latest models. 

More generally I think it's also pertinent to ask whether we should even be producing the same output as before. Does it really make sense to focus so much on writing internal documents, if previously the documents, when created with full human supervision and pondering, embodied the act of proving and weighing and idea in an auditable, human-attributable way. If the reason the document was written is no longher fulfilled, it is workslop anyway, does it really make sense. The same charge can be lobbied at essays at university, at least some types of such writing tasks. If the AI could one-shot it (this is of course not always the case, but can be more or less true), does it really make sense to think that its creation is still a useful proxy for internal rewiring of mental models in the writer? 

## The future of verification 

As AI gets better and better at making plausible sounding expert level arguments, there will need to be some anchored formalization. Otherwise the increases in output at that level will not yield the promised return, simply because proofreading and human conviction in the results will not keep up. One example is in mathematics, where AI can plausibly string together long arguments very quickly based on a simple prompt. To check that the output is correct usually requires a lot of time. And this time is expoentially (a very overused word, but used for consistency I guess) increasing in the sense that querys taken from some class of fixed prompt length induce outputs that are increasingly difficult to verify for a human. If the only queries that returned something sensible (and sensible looking) were simple ones, and the more complex ones consistently returned gibberish, verification is easy. Now many outputs, even to difficult questions, can not be dismissed out of hand. That is both amazing and a challenge, because it makes the formalization and proofreading bottleneck all the more acute. 
